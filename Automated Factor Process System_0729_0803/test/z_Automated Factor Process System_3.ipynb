{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Factor Process System "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to define:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define symbol to collect data\n",
    "symbol, interval, delay_minutes, start_year, start_month, start_day, end_year, end_month, end_day = 'BTCUSDT', '1h', 1, 2021, 1, 1, 2024, 6, 1\n",
    "### (end not included) #such as: 'BTCUSDT', '1h', 1, 2021, 1, 1, 2024, 6, 1\n",
    "\n",
    "# calculate return\n",
    "\n",
    "# feature processing method\n",
    "method = 'normalize' \n",
    "### method = normalize/standardize\n",
    "\n",
    "# train_test_split\n",
    "train_start, train_end, test_start, test_end = '2021-01-01', '2024-01-01', '2024-01-01', '2024-06-01' # can change\n",
    "\n",
    "# simply strategy threshold and cost\n",
    "threshold = 0.002\n",
    "cost = 0.002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import a_binance_data_collection as binance_data_collection\n",
    "import b1_calculate_return as cr\n",
    "import b2_class_calculate_return as ccr\n",
    "import c1_calculate_specific_factor as csf # we will change feature engineering(factor)\n",
    "import d_feature_preprocssing as feapre\n",
    "import e_train_test_split as tts \n",
    "import model_construction_1_linear as model_construction_1_linear # we will change model\n",
    "import f1_basic_strategy_backtest as bsb # we will change stategy\n",
    "import f2_basic_strategy_backtesting_class as bsbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binance_data = binance_data_collection.binance_data_collection(symbol, interval, delay_minutes, start_year, start_month, start_day, end_year, end_month, end_day) # symbol, interval, delay_minutes, start_year, start_month, start_day, end_year, end_month, end_day(end not included)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data  = pd.read_csv('BTCUSDT_2021_1_1_to_2024_6_1_with_1h.csv')\n",
    "# data['date_time'] = pd.to_datetime(data['date_time'])\n",
    "# data['real_time'] = pd.to_datetime(data['real_time'])\n",
    "# data['vwap'] = (data['close'] * data['volume']).cumsum() / data['volume'].cumsum()\n",
    "# print(data)\n",
    "\n",
    "# # simply process\n",
    "# for column in data.columns:\n",
    "#     median_value = data[column].median()\n",
    "#     data[column] = data[column].fillna(median_value)\n",
    "# print(data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot data\n",
    "# def plot_data(data, x_column, y_column, title):\n",
    "#     fig = go.Figure()\n",
    "#     fig.add_trace(go.Scatter(x=data[x_column], y=data[y_column], mode='lines', name=y_column))\n",
    "#     fig.update_layout(title=title, xaxis_title=x_column, yaxis_title=y_column)\n",
    "#     fig.show()\n",
    "\n",
    "# for column in data.columns[3:14]:\n",
    "#     plot_data(data, 'date_time', column, f'{column}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Factor calcualtion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # calcualte return\n",
    "# period_labels = [interval]\n",
    "# data = cr.compute_returns(data, period_labels=period_labels)\n",
    "\n",
    "# # period_labels = [interval]\n",
    "# # data = ccr.compute_returns(data, period_labels=period_labels, cost = cost)\n",
    "# # print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # caculate 101 worldquant factors\n",
    "# import c2_101Alpha as c2_101Alpha\n",
    "# df = data.copy()\n",
    "# df_fac = c2_101Alpha.get_alpha(df)\n",
    "# print(df_fac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # calculate specific factor\n",
    "# df = data.copy()\n",
    "# period_labels = period_labels\n",
    "\n",
    "# start_idx = df.columns.get_loc('volume') + 1\n",
    "# return_col = df.filter(like='return').columns.tolist()\n",
    "# end_idx = min(df.columns.get_loc(col) for col in return_col)\n",
    "# specific_factor_col = df.columns[start_idx:end_idx]\n",
    "\n",
    "# df_fac = csf.calculate_specific_factor(df, specific_factor_col, period_labels = period_labels)\n",
    "# # print(df_fac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tsfresh import extract_features\n",
    "# from tsfresh.utilities.dataframe_functions import impute\n",
    "# from tsfresh.utilities.distribution import MultiprocessingDistributor\n",
    "# from tsfresh import extract_features\n",
    "# from tsfresh.utilities.dataframe_functions import roll_time_series\n",
    "# train_start, train_end, test_start, test_end = train_start, train_end, test_start, test_end\n",
    "# train_df, test_df, Y, X, Y_train, X_train, Y_test, X_test = tts.train_test_split(df_fac, train_start, train_end, test_start, test_end)\n",
    "# timeseries = train_df[['close', 'volume', 'quote_asset_volume', 'number_of_trades', 'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume']].copy()\n",
    "# timeseries['code'] = 1\n",
    "# timeseries.reset_index(inplace=True)\n",
    "\n",
    "# data_roll = roll_time_series(timeseries, column_id='code', column_sort='date_time', max_timeshift=3, min_timeshift=1).drop(columns=['code'])\n",
    "\n",
    "\n",
    "# distributor = MultiprocessingDistributor(n_workers=1, disable_progressbar=False, progressbar_title=\"Feature Extraction\")\n",
    "    \n",
    "# extracted_features = extract_features(data_roll, column_id=\"id\", column_sort=\"date_time\", chunksize=60,distributor=distributor)\n",
    "# impute(extracted_features)\n",
    "\n",
    "# print(extracted_features)\n",
    "# extracted_features.to_csv('extracted_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# calculate commom factor\n",
    "## use tsfresh\n",
    "\n",
    "## use featuretools\n",
    "### soon...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Feature preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_df = df_fac.copy()\n",
    "\n",
    "# # return_data & feature_data processing\n",
    "# return_col = feature_df.filter(like='return').columns.tolist()\n",
    "# feature_df = feapre.handle_return(feature_df, return_col)\n",
    "# max_return_index = max(feature_df.columns.get_loc(col) for col in return_col)\n",
    "# feature_col = feature_df.columns[max_return_index + 1:].tolist()\n",
    "# feature_df = feapre.feature_preprocessing(feature_df, feature_col, method = method) # method = normalize/standardize\n",
    "\n",
    "# print(feature_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Model construction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_df = feature_df.copy()\n",
    "# model_df = model_df.to_csv('a.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = pd.read_csv('a.csv')\n",
    "model_df['date_time'] = pd.to_datetime(model_df['date_time'])\n",
    "model_df['real_time'] = pd.to_datetime(model_df['real_time'])\n",
    "model_df=model_df.set_index('date_time')\n",
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_df = feature_df.copy()\n",
    "train_start, train_end, test_start, test_end = train_start, train_end, test_start, test_end\n",
    "train_df, test_df, Y, X, Y_train, X_train, Y_test, X_test = tts.train_test_split(model_df, train_start, train_end, test_start, test_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model_construction_1_linear as model_construction_1_linear\n",
    "# result_df, test_df = model_construction_1_linear.model_construction_linear(train_df, test_df, Y, X, Y_train, X_train, Y_test, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model_construction_2_lasso as model_construction_2_lasso\n",
    "# result_df, test_df = model_construction_2_lasso.model_construction_lasso(train_df, test_df, Y, X, Y_train, X_train, Y_test, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model_construction_3_ridge as model_construction_3_ridge\n",
    "# result_df, test_df = model_construction_3_ridge.model_construction_ridge(train_df, test_df, Y, X, Y_train, X_train, Y_test, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model_construction_4_logistic as model_construction_4_logistic\n",
    "# result_df, test_df = model_construction_4_logistic.model_construction_logistic(train_df, test_df, Y, X, Y_train, X_train, Y_test, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model_construction_5_lda as model_construction_5_lda\n",
    "# result_df, test_df = model_construction_5_lda.model_construction_lda(train_df, test_df, Y, X, Y_train, X_train, Y_test, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model_construction_6_qda as model_construction_6_qda\n",
    "# result_df, test_df = model_construction_6_qda.model_construction_qda(train_df, test_df, Y, X, Y_train, X_train, Y_test, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model_construction_7_decision_trees_reg as model_construction_7_decision_trees_reg\n",
    "# result_df, test_df = model_construction_7_decision_trees_reg.model_construction_decision_trees(train_df, test_df, Y, X, Y_train, X_train, Y_test, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model_construction_8_decision_trees_class as model_construction_8_decision_trees_class\n",
    "# result_df, test_df = model_construction_8_decision_trees_class.model_construction_decision_trees(train_df, test_df, Y, X, Y_train, X_train, Y_test, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model_construction_9_random_forest_reg as model_construction_9_random_forest_reg\n",
    "# result_df, test_df = model_construction_9_random_forest_reg.model_construction_random_forest(train_df, test_df, Y, X, Y_train, X_train, Y_test, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model_construction_10_random_forest_class as model_construction_10_random_forest_class\n",
    "# result_df, test_df = model_construction_10_random_forest_class.model_construction_random_forest(train_df, test_df, Y, X, Y_train, X_train, Y_test, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model_construction_11_xgboost_reg as model_construction_11_xgboost_reg\n",
    "# result_df, test_df = model_construction_11_xgboost_reg.model_construction_xgboost(train_df, test_df, Y, X, Y_train, X_train, Y_test, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model_construction_12_xgboost_class as model_construction_12_xgboost_class\n",
    "# result_df, test_df = model_construction_12_xgboost_class.model_construction_xgboost(train_df, test_df, Y, X, Y_train, X_train, Y_test, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model_construction_13_adaboost_reg as model_construction_13_adaboost_reg\n",
    "# result_df, test_df = model_construction_13_adaboost_reg.model_construction_adaboost(train_df, test_df, Y, X, Y_train, X_train, Y_test, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model_construction_14_adaboost_class as model_construction_14_adaboost_class\n",
    "# result_df, test_df = model_construction_adaboost(train_df, test_df, Y, X, Y_train, X_train, Y_test, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model_construction_15_gbm_reg as model_construction_15_gbm_reg\n",
    "# result_df, test_df = model_construction_15_gbm_reg.model_construction_gbm(train_df, test_df, Y, X, Y_train, X_train, Y_test, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model_construction_16_gbm_class as model_construction_16_gbm_class\n",
    "# result_df, test_df = model_construction_16_gbm_class.model_construction_gbm(train_df, test_df, Y, X, Y_train, X_train, Y_test, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['close']\n",
    "for y_unique in result_df['Y'].unique():\n",
    "    columns_to_keep.append(y_unique)\n",
    "for x in result_df['X'].unique():\n",
    "    for y in result_df[result_df['X'] == x]['Y'].unique():\n",
    "        pred_col_name = f\"{x}___{y}_pred_rtn\"\n",
    "        if pred_col_name not in columns_to_keep:\n",
    "            columns_to_keep.append(pred_col_name)\n",
    "        \n",
    "model_result_df = test_df[columns_to_keep]\n",
    "model_result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_df = model_result_df.copy()\n",
    "back_df = bsb.basic_strategy_backtesting(back_df, threshold, cost)\n",
    "# back_df = bsbc.basic_strategy_backtesting(back_df, cost)\n",
    "back_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
